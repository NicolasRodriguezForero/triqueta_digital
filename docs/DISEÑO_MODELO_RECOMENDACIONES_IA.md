# DiseÃ±o del Sistema de RecomendaciÃ³n con Inteligencia Artificial

## Triqueta Digital

**Fecha:** Noviembre 2024  
**Estado:** DiseÃ±o Conceptual  
**VersiÃ³n:** 1.0

---

## ğŸ“‹ Tabla de Contenidos

1. [AnÃ¡lisis del Estado Actual](#1-anÃ¡lisis-del-estado-actual)
2. [Enfoques de Machine Learning para Recomendaciones](#2-enfoques-de-machine-learning-para-recomendaciones)
3. [Arquitectura del Sistema](#3-arquitectura-del-sistema)
4. [Datos Necesarios](#4-datos-necesarios)
5. [Estrategia de RecopilaciÃ³n de Datos](#5-estrategia-de-recopilaciÃ³n-de-datos)
6. [Modelos Propuestos](#6-modelos-propuestos)
7. [Pipeline de Entrenamiento](#7-pipeline-de-entrenamiento)
8. [EvaluaciÃ³n y MÃ©tricas](#8-evaluaciÃ³n-y-mÃ©tricas)
9. [Estrategia de Despliegue](#9-estrategia-de-despliegue)
10. [Roadmap de ImplementaciÃ³n](#10-roadmap-de-implementaciÃ³n)

---

## 1. AnÃ¡lisis del Estado Actual

### 1.1 Datos Disponibles Actualmente

#### **Datos de Usuarios:**

- âœ… **Perfil bÃ¡sico**: email, nombre, telÃ©fono, biografÃ­a
- âœ… **Preferencias explÃ­citas**:
  - `etiquetas_interes` (array de strings)
  - `localidad_preferida` (Chapinero, Santa Fe, La Candelaria)
  - `disponibilidad_horaria` (maÃ±ana, tarde, noche, fin_de_semana)
  - `nivel_actividad` (bajo, medio, alto)
- âœ… **Relaciones**: favoritos con timestamps

#### **Datos de Actividades:**

- âœ… **Contenido**: tÃ­tulo, descripciÃ³n, tipo, etiquetas
- âœ… **UbicaciÃ³n**: direcciÃ³n, coordenadas GPS, localidad
- âœ… **Temporal**: fecha_inicio, fecha_fin
- âœ… **Precio**: precio, es_gratis
- âœ… **Metadatos**: nivel_actividad, contacto, imagen_url, fuente
- âœ… **MÃ©tricas agregadas**: popularidad_favoritos, popularidad_vistas, popularidad_normalizada

#### **Interacciones Actuales:**

- âœ… **Favoritos**: usuario_id, actividad_id, fecha_guardado
- âœ… **Vistas**: registradas pero sin tracking individual (solo contador agregado)
- âŒ **No hay**: ratings explÃ­citos, tiempo de visualizaciÃ³n, clics, bÃºsquedas guardadas

### 1.2 Limitaciones Actuales

1. **Datos de interacciÃ³n limitados**: Solo favoritos explÃ­citos, sin seÃ±ales implÃ­citas detalladas
2. **Sin tracking de comportamiento**: No se registra tiempo en pÃ¡gina, scroll, clics en enlaces externos
3. **Sin feedback negativo**: No sabemos quÃ© actividades NO le gustaron al usuario
4. **Cold start problem**: Usuarios nuevos sin historial
5. **Sparsity**: Muchos usuarios, muchas actividades, pocas interacciones

---

## 2. Enfoques de Machine Learning para Recomendaciones

### 2.1 Tipos de Sistemas de RecomendaciÃ³n

#### **A. Collaborative Filtering (CF)**

**Ventajas:**

- No requiere caracterÃ­sticas de contenido
- Descubre patrones ocultos en interacciones
- Funciona bien con datos suficientes

**Desventajas:**

- Cold start problem (nuevos usuarios/actividades)
- Sparsity problem (matriz usuario-actividad muy dispersa)
- No explica por quÃ© se recomienda

**Aplicabilidad en Triqueta:**

- âš ï¸ Limitada inicialmente por falta de datos
- âœ… Ãštil cuando tengamos suficientes interacciones

#### **B. Content-Based Filtering**

**Ventajas:**

- Funciona con nuevos usuarios/actividades
- Explicable (basado en caracterÃ­sticas)
- No requiere datos de otros usuarios

**Desventajas:**

- Limitado a caracterÃ­sticas conocidas
- No descubre intereses nuevos
- Over-specialization

**Aplicabilidad en Triqueta:**

- âœ… Buena opciÃ³n inicial (ya tenemos caracterÃ­sticas)
- âœ… Complementa el sistema actual

#### **C. Hybrid Approach (Recomendado)**

**CombinaciÃ³n de:**

- Content-Based (etiquetas, localidad, tipo)
- Collaborative Filtering (similitud entre usuarios)
- Popularity-based (actividades trending)
- Deep Learning (embeddings, representaciones densas)

**Aplicabilidad en Triqueta:**

- âœ… **MEJOR OPCIÃ“N**: Combina fortalezas de ambos enfoques
- âœ… Mitiga cold start con content-based
- âœ… Mejora con mÃ¡s datos usando CF

### 2.2 Algoritmos EspecÃ­ficos Propuestos

#### **OpciÃ³n 1: Matrix Factorization (SVD, NMF)**

- **TÃ©cnica**: FactorizaciÃ³n de matriz usuario-actividad
- **Ventajas**: Simple, interpretable, escalable
- **Requisitos**: Matriz de interacciones densa
- **Uso**: Cuando tengamos ~1000+ interacciones

#### **OpciÃ³n 2: Deep Learning (Neural Collaborative Filtering)**

- **TÃ©cnica**: Red neuronal para aprender embeddings
- **Ventajas**: Captura patrones complejos, no lineales
- **Requisitos**: MÃ¡s datos, mÃ¡s recursos computacionales
- **Uso**: Fase avanzada con muchos datos

#### **OpciÃ³n 3: Factorization Machines / Wide & Deep**

- **TÃ©cnica**: Combina features categÃ³ricas y numÃ©ricas
- **Ventajas**: Maneja features mixtas, explicable
- **Requisitos**: Features bien definidas
- **Uso**: **RECOMENDADO para inicio** - aprovecha datos existentes

#### **OpciÃ³n 4: Two-Tower Architecture (Embeddings)**

- **TÃ©cnica**: Dos redes (usuario y actividad) que producen embeddings
- **Ventajas**: Escalable, permite bÃºsqueda rÃ¡pida (ANN)
- **Requisitos**: Datos de entrenamiento suficientes
- **Uso**: Fase de producciÃ³n con muchos usuarios

---

## 3. Arquitectura del Sistema

### 3.1 Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND / API                            â”‚
â”‚              (FastAPI - Endpoint actual)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SERVICIO DE RECOMENDACIONES                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Recommendation Service (Actual)                      â”‚  â”‚
â”‚  â”‚  - LÃ³gica hÃ­brida simple                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                      â”‚
â”‚                       â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ML Recommendation Service (Nuevo)                    â”‚  â”‚
â”‚  â”‚  - Modelo entrenado                                    â”‚  â”‚
â”‚  â”‚  - Predicciones en tiempo real                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
        â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL â”‚ â”‚    Redis     â”‚ â”‚  ML Service  â”‚
â”‚   (Datos)    â”‚ â”‚   (Cache)    â”‚ â”‚  (Modelo)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Feature Store       â”‚
            â”‚  (Features procesadas)â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Componentes del Sistema ML

#### **A. Feature Engineering Pipeline**

- ExtracciÃ³n de features de usuarios
- ExtracciÃ³n de features de actividades
- Features de interacciÃ³n (historial, frecuencia)
- Features temporales (dÃ­a de semana, hora, estaciÃ³n)
- Features geogrÃ¡ficas (distancia, densidad de actividades)

#### **B. Model Training Service**

- Entrenamiento offline (batch)
- ValidaciÃ³n cruzada
- SelecciÃ³n de hiperparÃ¡metros
- Versionado de modelos

#### **C. Model Serving Service**

- API REST para predicciones
- Carga de modelos entrenados
- Preprocesamiento en tiempo real
- Post-procesamiento (filtros, diversidad)

#### **D. Monitoring & Evaluation**

- MÃ©tricas en tiempo real
- A/B testing framework
- Logging de predicciones
- Alertas de degradaciÃ³n

---

## 4. Datos Necesarios

### 4.1 Datos Actuales (Ya Disponibles)

#### **Features de Usuario:**

```python
user_features = {
    # ExplÃ­citas
    'etiquetas_interes': ['mÃºsica', 'teatro', 'arte'],
    'localidad_preferida': 'Chapinero',
    'disponibilidad_horaria': 'tarde',
    'nivel_actividad': 'medio',

    # ImplÃ­citas (a calcular)
    'total_favoritos': 15,
    'diversidad_tipos': 0.67,  # tipos Ãºnicos / total favoritos
    'diversidad_localidades': 0.33,
    'antiguedad_cuenta_dias': 120,
    'frecuencia_actividad': 0.5,  # favoritos por semana
}
```

#### **Features de Actividad:**

```python
activity_features = {
    # Contenido
    'tipo': 'cultura',
    'etiquetas': ['mÃºsica', 'concierto'],
    'nivel_actividad': 'medio',
    'localidad': 'Chapinero',

    # Temporal
    'fecha_inicio': '2024-11-25 19:00:00',
    'dia_semana': 1,  # lunes
    'hora': 19,
    'es_fin_de_semana': False,
    'dias_hasta_evento': 3,

    # GeogrÃ¡fico
    'lat': 4.6533,
    'lng': -74.0836,
    'precio': 0,
    'es_gratis': True,

    # Popularidad
    'popularidad_favoritos': 45,
    'popularidad_vistas': 12.5,
    'popularidad_normalizada': 0.75,

    # Texto (para NLP)
    'titulo': 'Concierto de Jazz',
    'descripcion': '...',
}
```

### 4.2 Datos que Necesitamos Recopilar

#### **A. Interacciones ExplÃ­citas (Alta Prioridad)**

1. **Ratings/Calificaciones**

   ```python
   class Rating(Base):
       usuario_id: int
       actividad_id: UUID
       rating: int  # 1-5 estrellas
       fecha: datetime
       comentario: Optional[str]
   ```

   - **Por quÃ©**: Feedback directo de preferencia
   - **CuÃ¡ndo**: DespuÃ©s de asistir a actividad o ver detalle

2. **Feedback ExplÃ­cito**
   ```python
   class Feedback(Base):
       usuario_id: int
       actividad_id: UUID
       tipo: str  # 'like', 'dislike', 'maybe'
       fecha: datetime
   ```
   - **Por quÃ©**: SeÃ±ales positivas y negativas
   - **CuÃ¡ndo**: En lista de recomendaciones o bÃºsqueda

#### **B. Interacciones ImplÃ­citas (Alta Prioridad)**

1. **Eventos de VisualizaciÃ³n Detallados**

   ```python
   class ActivityView(Base):
       usuario_id: Optional[int]  # null si anÃ³nimo
       actividad_id: UUID
       timestamp: datetime
       tiempo_en_pagina: int  # segundos
       scroll_depth: float  # 0-1
       clicks_enlace_externo: bool
       origen: str  # 'busqueda', 'recomendacion', 'favoritos', 'lista'
   ```

   - **Por quÃ©**: SeÃ±al implÃ­cita de interÃ©s
   - **CuÃ¡ndo**: Cada vez que se ve detalle de actividad

2. **Eventos de BÃºsqueda**

   ```python
   class SearchEvent(Base):
       usuario_id: Optional[int]
       query: str
       filtros: dict  # JSON
       resultados_encontrados: int
       actividades_clicked: List[UUID]
       timestamp: datetime
   ```

   - **Por quÃ©**: IntenciÃ³n explÃ­cita del usuario
   - **CuÃ¡ndo**: Cada bÃºsqueda realizada

3. **Eventos de NavegaciÃ³n**
   ```python
   class NavigationEvent(Base):
       usuario_id: Optional[int]
       actividad_id: UUID
       accion: str  # 'view_list', 'apply_filter', 'sort_by'
       parametros: dict  # JSON
       timestamp: datetime
   ```
   - **Por quÃ©**: Patrones de exploraciÃ³n
   - **CuÃ¡ndo**: Interacciones con listas y filtros

#### **C. Datos Contextuales (Media Prioridad)**

1. **Datos Temporales Mejorados**

   - DÃ­a de la semana de interacciÃ³n
   - Hora del dÃ­a
   - EstaciÃ³n del aÃ±o
   - Festivos/eventos especiales

2. **Datos GeogrÃ¡ficos Mejorados**

   - Distancia desde ubicaciÃ³n del usuario (si disponible)
   - Densidad de actividades en Ã¡rea
   - Accesibilidad (transporte pÃºblico)

3. **Datos de Dispositivo**
   ```python
   class UserSession(Base):
       usuario_id: Optional[int]
       device_type: str  # 'mobile', 'desktop', 'tablet'
       browser: str
       ip_address: str  # hasheado
       timestamp: datetime
   ```
   - **Por quÃ©**: Contexto de uso
   - **CuÃ¡ndo**: Cada sesiÃ³n

#### **D. Datos de Resultado (Alta Prioridad)**

1. **Asistencia Real**
   ```python
   class Attendance(Base):
       usuario_id: int
       actividad_id: UUID
       asistio: bool
       fecha_asistencia: datetime
       rating_post_evento: Optional[int]
       comentario: Optional[str]
   ```
   - **Por quÃ©**: Ground truth para validar recomendaciones
   - **CuÃ¡ndo**: DespuÃ©s del evento (encuesta opcional)

---

## 5. Estrategia de RecopilaciÃ³n de Datos

### 5.1 Fase 1: InstrumentaciÃ³n MÃ­nima (Inmediata)

**Objetivo**: Recopilar datos bÃ¡sicos sin cambios mayores en UX

#### **Implementar:**

1. âœ… **Tracking de vistas detalladas** (ya existe parcialmente)

   - Agregar: tiempo en pÃ¡gina, scroll depth
   - Agregar: origen de la vista (recomendaciÃ³n vs bÃºsqueda)

2. âœ… **Tracking de bÃºsquedas**

   - Query, filtros aplicados, resultados clickeados

3. âœ… **Sistema de feedback rÃ¡pido**
   - BotÃ³n "Me gusta" / "No me interesa" en recomendaciones
   - Sin requerir rating completo

#### **MÃ©tricas objetivo:**

- 1000+ eventos de visualizaciÃ³n por semana
- 500+ bÃºsquedas por semana
- 200+ feedbacks por semana

### 5.2 Fase 2: Engagement Mejorado (1-2 meses)

**Objetivo**: Aumentar calidad y cantidad de seÃ±ales

#### **Implementar:**

1. **Sistema de ratings**

   - Rating 1-5 estrellas despuÃ©s de ver detalle
   - Opcional pero incentivado

2. **Tracking de asistencia**

   - Encuesta post-evento (opcional)
   - "Â¿Asististe a esta actividad?"

3. **Mejoras en tracking**
   - Tiempo de visualizaciÃ³n preciso
   - Clicks en enlaces externos
   - Scroll completo

#### **MÃ©tricas objetivo:**

- 5000+ eventos por semana
- 1000+ ratings por semana
- 100+ confirmaciones de asistencia por semana

### 5.3 Fase 3: Datos Ricos (3-6 meses)

**Objetivo**: Datos suficientes para modelos avanzados

#### **Implementar:**

1. **Datos contextuales completos**

   - UbicaciÃ³n del usuario (opcional, con consentimiento)
   - Historial de navegaciÃ³n completo

2. **A/B testing framework**

   - Comparar diferentes modelos
   - Medir impacto en engagement

3. **Feedback loop cerrado**
   - Recomendaciones â†’ InteracciÃ³n â†’ Feedback â†’ Mejora

#### **MÃ©tricas objetivo:**

- 10,000+ eventos por semana
- 2000+ ratings por semana
- 500+ asistencias confirmadas por semana

---

## 6. Modelos Propuestos

### 6.1 Modelo Inicial: Factorization Machines (FM)

**JustificaciÃ³n**:

- Maneja features categÃ³ricas y numÃ©ricas
- No requiere muchos datos para empezar
- Explicable y eficiente

**Arquitectura**:

```
Input Features:
â”œâ”€â”€ Usuario Features (one-hot + embeddings)
â”‚   â”œâ”€â”€ etiquetas_interes (multi-hot)
â”‚   â”œâ”€â”€ localidad_preferida (categorical)
â”‚   â”œâ”€â”€ nivel_actividad (categorical)
â”‚   â””â”€â”€ estadÃ­sticas (numÃ©ricas)
â”‚
â”œâ”€â”€ Actividad Features (one-hot + embeddings)
â”‚   â”œâ”€â”€ tipo (categorical)
â”‚   â”œâ”€â”€ etiquetas (multi-hot)
â”‚   â”œâ”€â”€ localidad (categorical)
â”‚   â”œâ”€â”€ nivel_actividad (categorical)
â”‚   â””â”€â”€ popularidad (numÃ©rica)
â”‚
â””â”€â”€ InteracciÃ³n Features
    â”œâ”€â”€ distancia_usuario_actividad (numÃ©rica)
    â”œâ”€â”€ match_etiquetas (numÃ©rica)
    â”œâ”€â”€ match_localidad (binaria)
    â””â”€â”€ dias_hasta_evento (numÃ©rica)

â†“

Factorization Machine Layer
- Aprende interacciones entre features
- Embeddings de dimensiÃ³n k (e.g., 32)

â†“

Output: Probabilidad de interacciÃ³n (0-1)
```

**Entrenamiento**:

- **Objetivo**: Predecir si usuario interactuarÃ¡ con actividad
- **Etiquetas**: 1 si favorito/rating alto, 0 si no interactuÃ³ o rating bajo
- **Algoritmo**: SGD o Adam optimizer
- **RegularizaciÃ³n**: L2 para evitar overfitting

### 6.2 Modelo Intermedio: Wide & Deep Learning

**JustificaciÃ³n**:

- Combina memorizaciÃ³n (wide) y generalizaciÃ³n (deep)
- Mejor para datos mixtos
- Escalable

**Arquitectura**:

```
Wide Component (MemorizaciÃ³n):
â”œâ”€â”€ Features cruzadas importantes
â”‚   â”œâ”€â”€ etiquetas_usuario Ã— etiquetas_actividad
â”‚   â”œâ”€â”€ localidad_usuario Ã— localidad_actividad
â”‚   â””â”€â”€ tipo Ã— nivel_actividad
â””â”€â”€ Linear Model

Deep Component (GeneralizaciÃ³n):
â”œâ”€â”€ Embeddings de features categÃ³ricas
â”œâ”€â”€ Features numÃ©ricas normalizadas
â”œâ”€â”€ Fully Connected Layers (3-4 capas)
â”‚   â”œâ”€â”€ 128 â†’ 64 â†’ 32 â†’ 16
â”‚   â””â”€â”€ ReLU activations
â””â”€â”€ Output Layer

â†“

CombinaciÃ³n: Wide + Deep â†’ Probabilidad final
```

### 6.3 Modelo Avanzado: Two-Tower Neural Network

**JustificaciÃ³n**:

- Escalable a millones de usuarios/actividades
- Permite bÃºsqueda rÃ¡pida con ANN (Approximate Nearest Neighbors)
- State-of-the-art en sistemas de recomendaciÃ³n

**Arquitectura**:

```
User Tower:
â”œâ”€â”€ User ID Embedding (lookup table)
â”œâ”€â”€ User Features
â”‚   â”œâ”€â”€ etiquetas_interes (embedding)
â”‚   â”œâ”€â”€ localidad_preferida (embedding)
â”‚   â””â”€â”€ estadÃ­sticas (dense)
â”œâ”€â”€ Fully Connected Layers
â”‚   â””â”€â”€ 64 â†’ 32 â†’ 16
â””â”€â”€ User Embedding (16-dim)

Activity Tower:
â”œâ”€â”€ Activity ID Embedding (lookup table)
â”œâ”€â”€ Activity Features
â”‚   â”œâ”€â”€ tipo (embedding)
â”‚   â”œâ”€â”€ etiquetas (embedding)
â”‚   â”œâ”€â”€ localidad (embedding)
â”‚   â””â”€â”€ popularidad (dense)
â”œâ”€â”€ Fully Connected Layers
â”‚   â””â”€â”€ 64 â†’ 32 â†’ 16
â””â”€â”€ Activity Embedding (16-dim)

â†“

Similarity: Cosine(User Embedding, Activity Embedding)
```

**Ventajas**:

- PredicciÃ³n rÃ¡pida: solo calcular similitud
- BÃºsqueda eficiente: usar ANN (FAISS, Annoy)
- Escalable: embeddings pre-computados

### 6.4 Modelo HÃ­brido Final (Recomendado)

**CombinaciÃ³n de mÃºltiples modelos**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Ensemble de Modelos                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  1. Factorization Machine (30%)         â”‚
â”‚     - Features cruzadas                 â”‚
â”‚                                          â”‚
â”‚  2. Two-Tower Neural (50%)              â”‚
â”‚     - Embeddings de usuario/actividad   â”‚
â”‚                                          â”‚
â”‚  3. Content-Based Filter (10%)          â”‚
â”‚     - Similitud de etiquetas            â”‚
â”‚                                          â”‚
â”‚  4. Popularity Boost (10%)              â”‚
â”‚     - Actividades trending              â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Weighted Average / Stacking
              â†“
    Score Final (0-1)
```

**Ventajas**:

- Robustez: mÃºltiples modelos compensan errores
- Flexibilidad: ajustar pesos segÃºn performance
- Explicabilidad: cada componente aporta explicaciÃ³n

---

## 7. Pipeline de Entrenamiento

### 7.1 Pipeline Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATA COLLECTION                           â”‚
â”‚  PostgreSQL â†’ Raw Events â†’ Feature Store                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FEATURE ENGINEERING                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ User Featuresâ”‚  â”‚Activity Feat.â”‚  â”‚Interaction   â”‚      â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚Features      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                       â”‚                                      â”‚
â”‚                       â–¼                                      â”‚
â”‚              Feature Store (Parquet/CSV)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATA PREPARATION                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Train/Val/   â”‚  â”‚ Negative     â”‚  â”‚ Data         â”‚     â”‚
â”‚  â”‚ Test Split   â”‚  â”‚ Sampling     â”‚  â”‚ Augmentation â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODEL TRAINING                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Hyperparameterâ”‚ â”‚ Cross-        â”‚  â”‚ Model        â”‚     â”‚
â”‚  â”‚ Tuning        â”‚ â”‚ Validation   â”‚  â”‚ Selection    â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODEL EVALUATION                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Metrics      â”‚  â”‚ A/B Testing  â”‚  â”‚ Error        â”‚     â”‚
â”‚  â”‚ Calculation  â”‚  â”‚ Framework    â”‚  â”‚ Analysis     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODEL DEPLOYMENT                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Model        â”‚  â”‚ Versioning  â”‚  â”‚ Monitoring   â”‚       â”‚
â”‚  â”‚ Serializationâ”‚  â”‚ (MLflow)    â”‚  â”‚ (Prometheus)  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 Feature Engineering Detallado

#### **A. User Features**

```python
def extract_user_features(user_id, db):
    user = get_user(user_id, db)
    profile = user.perfil
    favorites = get_user_favorites(user_id, db)

    features = {
        # CategÃ³ricas (one-hot encoding)
        'localidad_preferida_chapinero': 1 if profile.localidad_preferida == 'Chapinero' else 0,
        'localidad_preferida_santafe': 1 if profile.localidad_preferida == 'Santa Fe' else 0,
        'localidad_preferida_candelaria': 1 if profile.localidad_preferida == 'La Candelaria' else 0,
        'nivel_actividad_bajo': 1 if profile.nivel_actividad == 'bajo' else 0,
        'nivel_actividad_medio': 1 if profile.nivel_actividad == 'medio' else 0,
        'nivel_actividad_alto': 1 if profile.nivel_actividad == 'alto' else 0,

        # Multi-hot encoding para etiquetas
        'etiqueta_musica': 1 if 'mÃºsica' in profile.etiquetas_interes else 0,
        'etiqueta_teatro': 1 if 'teatro' in profile.etiquetas_interes else 0,
        # ... para cada etiqueta posible

        # NumÃ©ricas
        'total_favoritos': len(favorites),
        'diversidad_tipos': len(set(f.tipo for f in favorites)) / max(len(favorites), 1),
        'diversidad_localidades': len(set(f.localidad for f in favorites)) / max(len(favorites), 1),
        'antiguedad_cuenta_dias': (datetime.now() - user.created_at).days,
        'frecuencia_favoritos_semana': len(favorites) / max((datetime.now() - user.created_at).days / 7, 1),

        # EstadÃ­sticas de favoritos
        'promedio_precio_favoritos': np.mean([f.precio for f in favorites]) if favorites else 0,
        'ratio_gratis_favoritos': sum(1 for f in favorites if f.es_gratis) / max(len(favorites), 1),
    }

    return features
```

#### **B. Activity Features**

```python
def extract_activity_features(activity_id, db):
    activity = get_activity(activity_id, db)

    features = {
        # CategÃ³ricas
        'tipo_cultura': 1 if activity.tipo == 'cultura' else 0,
        'tipo_deporte': 1 if activity.tipo == 'deporte' else 0,
        'tipo_recreacion': 1 if activity.tipo == 'recreacion' else 0,
        'localidad_chapinero': 1 if activity.localidad == 'Chapinero' else 0,
        # ... similar para otras localidades

        # Multi-hot para etiquetas
        'etiqueta_musica': 1 if 'mÃºsica' in activity.etiquetas else 0,
        # ... para cada etiqueta

        # NumÃ©ricas
        'popularidad_favoritos': activity.popularidad_favoritos,
        'popularidad_vistas': float(activity.popularidad_vistas),
        'popularidad_normalizada': float(activity.popularidad_normalizada),
        'precio': float(activity.precio),
        'es_gratis': 1 if activity.es_gratis else 0,

        # Temporales
        'dias_hasta_evento': (activity.fecha_inicio - datetime.now()).days,
        'dia_semana': activity.fecha_inicio.weekday(),
        'hora': activity.fecha_inicio.hour,
        'es_fin_de_semana': 1 if activity.fecha_inicio.weekday() >= 5 else 0,

        # GeogrÃ¡ficas
        'lat': float(activity.ubicacion_lat),
        'lng': float(activity.ubicacion_lng),
    }

    return features
```

#### **C. Interaction Features**

```python
def extract_interaction_features(user_id, activity_id, db):
    user = get_user(user_id, db)
    activity = get_activity(activity_id, db)
    user_favorites = get_user_favorites(user_id, db)

    # Match features
    user_tags = set(user.perfil.etiquetas_interes)
    activity_tags = set(activity.etiquetas)
    matching_tags = user_tags & activity_tags

    features = {
        # Match scores
        'match_etiquetas_count': len(matching_tags),
        'match_etiquetas_ratio': len(matching_tags) / max(len(user_tags), 1),
        'match_localidad': 1 if user.perfil.localidad_preferida == activity.localidad else 0,
        'match_nivel_actividad': 1 if user.perfil.nivel_actividad == activity.nivel_actividad else 0,
        'match_tipo': 1 if activity.tipo in [f.tipo for f in user_favorites] else 0,

        # Distancia (si tenemos ubicaciÃ³n del usuario)
        'distancia_km': calculate_distance(user_location, activity_location) if user_location else None,

        # Contexto temporal
        'match_disponibilidad': check_time_match(user.perfil.disponibilidad_horaria, activity.fecha_inicio),
    }

    return features
```

### 7.3 Negative Sampling

**Problema**: Solo tenemos interacciones positivas (favoritos). Necesitamos ejemplos negativos.

**Estrategias**:

1. **Random Negative Sampling**

   - Para cada positivo, muestrear N actividades aleatorias que el usuario NO favoritÃ³
   - Ratio positivo:negativo = 1:4 (tÃ­pico)

2. **Popularity-based Negative Sampling**

   - Muestrear actividades populares que el usuario NO vio
   - MÃ¡s realista (es mÃ¡s probable que las haya visto)

3. **Hard Negative Sampling**
   - Actividades similares a favoritos pero que NO fueron favoritadas
   - MÃ¡s difÃ­cil, mejora el modelo

```python
def generate_negative_samples(user_id, positive_interactions, all_activities, ratio=4):
    user_favorited_ids = {fav.actividad_id for fav in positive_interactions}

    # Actividades que el usuario NO favoritÃ³
    negative_candidates = [
        act for act in all_activities
        if act.id not in user_favorited_ids and act.estado == 'activa'
    ]

    # Estrategia: 50% random, 50% popular
    n_negatives = len(positive_interactions) * ratio

    random_negatives = random.sample(negative_candidates, n_negatives // 2)

    popular_negatives = sorted(
        [act for act in negative_candidates if act not in random_negatives],
        key=lambda x: x.popularidad_normalizada,
        reverse=True
    )[:n_negatives // 2]

    return random_negatives + popular_negatives
```

### 7.4 Entrenamiento

```python
# PseudocÃ³digo de entrenamiento

# 1. Cargar datos
positive_samples = load_favorites()  # (user_id, activity_id, label=1)
all_activities = load_all_activities()

# 2. Generar muestras negativas
negative_samples = generate_negative_samples(positive_samples, all_activities)

# 3. Extraer features
X_train = []
y_train = []

for user_id, activity_id, label in positive_samples + negative_samples:
    user_features = extract_user_features(user_id)
    activity_features = extract_activity_features(activity_id)
    interaction_features = extract_interaction_features(user_id, activity_id)

    features = combine_features(user_features, activity_features, interaction_features)
    X_train.append(features)
    y_train.append(label)

# 4. Entrenar modelo
model = FactorizationMachine(n_features=len(X_train[0]), k=32)
model.fit(X_train, y_train, epochs=50, batch_size=256)

# 5. Evaluar
predictions = model.predict(X_test)
metrics = calculate_metrics(y_test, predictions)
```

---

## 8. EvaluaciÃ³n y MÃ©tricas

### 8.1 MÃ©tricas Offline

#### **A. MÃ©tricas de ClasificaciÃ³n**

- **AUC-ROC**: Ãrea bajo curva ROC (mejor para ranking)
- **Precision@K**: PrecisiÃ³n en top K recomendaciones
- **Recall@K**: Cobertura en top K
- **F1-Score**: Balance entre precisiÃ³n y recall

#### **B. MÃ©tricas de Ranking**

- **NDCG@K** (Normalized Discounted Cumulative Gain)

  - Mide calidad del ranking
  - Penaliza items relevantes en posiciones bajas
  - **Objetivo**: NDCG@10 > 0.5

- **MAP@K** (Mean Average Precision)

  - Promedio de precisiÃ³n promedio
  - **Objetivo**: MAP@10 > 0.3

- **MRR** (Mean Reciprocal Rank)
  - PosiciÃ³n del primer item relevante
  - **Objetivo**: MRR > 0.4

#### **C. MÃ©tricas de Diversidad**

- **Coverage**: % de actividades recomendadas al menos una vez
- **Diversity**: Similitud promedio entre recomendaciones
- **Novelty**: Actividades poco populares recomendadas

### 8.2 MÃ©tricas Online (A/B Testing)

#### **A. MÃ©tricas de Engagement**

- **CTR** (Click-Through Rate): % de recomendaciones clickeadas
- **Conversion Rate**: % que agrega a favoritos
- **Time to Interaction**: Tiempo hasta primera interacciÃ³n

#### **B. MÃ©tricas de Negocio**

- **Retention Rate**: % de usuarios que regresan
- **Session Length**: DuraciÃ³n promedio de sesiÃ³n
- **Activities Discovered**: Nuevas actividades descubiertas

### 8.3 Framework de EvaluaciÃ³n

```python
class RecommendationEvaluator:
    def evaluate_offline(self, model, test_data):
        """EvaluaciÃ³n offline con mÃ©tricas estÃ¡ndar"""
        predictions = model.predict(test_data)

        metrics = {
            'auc_roc': roc_auc_score(test_data.labels, predictions),
            'ndcg@10': ndcg_score(test_data, predictions, k=10),
            'map@10': map_score(test_data, predictions, k=10),
            'precision@10': precision_at_k(test_data, predictions, k=10),
            'recall@10': recall_at_k(test_data, predictions, k=10),
        }

        return metrics

    def evaluate_online(self, experiment_results):
        """EvaluaciÃ³n online de A/B test"""
        control_group = experiment_results['control']
        treatment_group = experiment_results['treatment']

        metrics = {
            'ctr_improvement': (
                treatment_group['ctr'] - control_group['ctr']
            ) / control_group['ctr'],
            'conversion_improvement': (
                treatment_group['conversion_rate'] - control_group['conversion_rate']
            ) / control_group['conversion_rate'],
            'statistical_significance': self.chi_square_test(
                control_group, treatment_group
            ),
        }

        return metrics
```

---

## 9. Estrategia de Despliegue

### 9.1 Arquitectura de Despliegue

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRODUCTION ENVIRONMENT                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         FastAPI Backend (Actual)                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  Recommendation Service                        â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Fallback al sistema actual                  â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Llamada a ML Service si disponible          â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                      â”‚
â”‚                       â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         ML Serving Service (Nuevo)                     â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  Model Loader                                 â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Carga modelo entrenado                     â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Versionado (MLflow)                        â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚  â”‚  Prediction Service                           â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Preprocesamiento                           â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - PredicciÃ³n batch/online                    â”‚   â”‚  â”‚
â”‚  â”‚  â”‚  - Post-procesamiento                        â”‚   â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                       â”‚                                      â”‚
â”‚                       â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Feature Store                                 â”‚  â”‚
â”‚  â”‚  - Features pre-computadas                           â”‚  â”‚
â”‚  â”‚  - Cache de embeddings                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TRAINING ENVIRONMENT (Offline)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Data Pipeline                                        â”‚ â”‚
â”‚  â”‚  - ETL de PostgreSQL â†’ Feature Store                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Training Pipeline                                   â”‚ â”‚
â”‚  â”‚  - Feature Engineering                               â”‚ â”‚
â”‚  â”‚  - Model Training                                    â”‚ â”‚
â”‚  â”‚  - Evaluation                                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Model Registry (MLflow)                             â”‚ â”‚
â”‚  â”‚  - Versionado de modelos                              â”‚ â”‚
â”‚  â”‚  - Tracking de experimentos                          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2 Estrategia de Rollout

#### **Fase 1: Shadow Mode (1-2 semanas)**

- Modelo ML corre en paralelo con sistema actual
- No afecta recomendaciones mostradas
- Comparar predicciones offline
- Validar latencia y performance

#### **Fase 2: A/B Testing (2-4 semanas)**

- 10% de trÃ¡fico al modelo ML
- 90% al sistema actual
- Medir mÃ©tricas de engagement
- Ajustar segÃºn resultados

#### **Fase 3: Canary Deployment (1-2 semanas)**

- 50% de trÃ¡fico al modelo ML
- Monitoreo intensivo
- Rollback automÃ¡tico si mÃ©tricas degradan

#### **Fase 4: Full Rollout**

- 100% de trÃ¡fico al modelo ML
- Sistema actual como fallback
- Monitoreo continuo

### 9.3 Monitoreo en ProducciÃ³n

#### **MÃ©tricas a Monitorear**:

1. **Latencia**: P95 < 100ms
2. **Throughput**: Requests por segundo
3. **Error Rate**: < 0.1%
4. **Cache Hit Rate**: > 80%
5. **Model Drift**: Cambios en distribuciÃ³n de features

#### **Alertas**:

- Latencia > 200ms
- Error rate > 1%
- Cache hit rate < 50%
- DegradaciÃ³n de mÃ©tricas de negocio > 10%

---

## 10. Roadmap de ImplementaciÃ³n

### 10.1 Fase 1: PreparaciÃ³n (Mes 1-2)

**Objetivos**:

- Instrumentar recopilaciÃ³n de datos
- Establecer infraestructura bÃ¡sica

**Tareas**:

1. âœ… Crear tablas para eventos de interacciÃ³n
2. âœ… Implementar tracking de vistas detalladas
3. âœ… Implementar tracking de bÃºsquedas
4. âœ… Crear Feature Store bÃ¡sico
5. âœ… Establecer pipeline de datos (ETL)

**Entregables**:

- Base de datos con eventos
- Dashboard de mÃ©tricas de datos
- 1000+ eventos recopilados

### 10.2 Fase 2: Modelo MVP (Mes 3-4)

**Objetivos**:

- Entrenar primer modelo funcional
- Validar enfoque

**Tareas**:

1. âœ… Feature engineering completo
2. âœ… Implementar Factorization Machine
3. âœ… Pipeline de entrenamiento
4. âœ… EvaluaciÃ³n offline
5. âœ… API de predicciÃ³n bÃ¡sica

**Entregables**:

- Modelo entrenado con AUC > 0.65
- API de predicciÃ³n funcionando
- Reporte de evaluaciÃ³n

### 10.3 Fase 3: IntegraciÃ³n (Mes 5-6)

**Objetivos**:

- Integrar modelo en producciÃ³n
- A/B testing

**Tareas**:

1. âœ… IntegraciÃ³n con backend FastAPI
2. âœ… Sistema de cache para predicciones
3. âœ… A/B testing framework
4. âœ… Monitoreo y alertas
5. âœ… DocumentaciÃ³n

**Entregables**:

- Modelo en producciÃ³n (shadow mode)
- Dashboard de monitoreo
- Resultados de A/B test

### 10.4 Fase 4: OptimizaciÃ³n (Mes 7-12)

**Objetivos**:

- Mejorar modelo con mÃ¡s datos
- Optimizar performance

**Tareas**:

1. âœ… Recopilar mÃ¡s datos (objetivo: 10K+ eventos)
2. âœ… Experimentar con modelos avanzados (Wide & Deep, Two-Tower)
3. âœ… Optimizar features
4. âœ… Tuning de hiperparÃ¡metros
5. âœ… Implementar ensemble

**Entregables**:

- Modelo mejorado (AUC > 0.75)
- Sistema de recomendaciÃ³n hÃ­brido
- Mejora medible en engagement

---

## 11. Consideraciones TÃ©cnicas

### 11.1 Stack TecnolÃ³gico Propuesto

#### **Machine Learning**:

- **Framework**: PyTorch o TensorFlow
- **LibrerÃ­as**:
  - `scikit-learn` para modelos simples
  - `pytorch-fm` o `xlearn` para Factorization Machines
  - `tensorflow-recommenders` para modelos avanzados

#### **Feature Store**:

- **OpciÃ³n 1**: PostgreSQL (simple, ya existe)
- **OpciÃ³n 2**: Redis (rÃ¡pido, para features frecuentes)
- **OpciÃ³n 3**: Feast (feature store dedicado, avanzado)

#### **Model Serving**:

- **OpciÃ³n 1**: FastAPI endpoint (simple, integrado)
- **OpciÃ³n 2**: TensorFlow Serving (escalable)
- **OpciÃ³n 3**: TorchServe (si usamos PyTorch)

#### **MLOps**:

- **MLflow**: Tracking de experimentos y versionado
- **Docker**: Contenedores para entrenamiento y serving
- **Kubernetes**: OrquestaciÃ³n (opcional, para escala)

### 11.2 Requisitos de Infraestructura

#### **Desarrollo**:

- CPU: 4+ cores
- RAM: 16GB+
- GPU: Opcional (acelera entrenamiento)

#### **ProducciÃ³n**:

- CPU: 8+ cores (para serving)
- RAM: 32GB+
- Storage: 100GB+ (modelos, features)

### 11.3 Costos Estimados

#### **Desarrollo**:

- Tiempo: 6-12 meses (1 desarrollador ML)
- Infraestructura: $50-200/mes (cloud)

#### **ProducciÃ³n**:

- Servidor ML: $100-500/mes
- Storage: $20-50/mes
- **Total**: ~$200-800/mes

---

## 12. Riesgos y Mitigaciones

### 12.1 Riesgos Identificados

1. **Falta de datos suficientes**

   - **Riesgo**: Modelo no aprende patrones Ãºtiles
   - **MitigaciÃ³n**: Empezar con modelo simple, usar content-based como fallback

2. **Cold start problem**

   - **Riesgo**: Nuevos usuarios sin historial
   - **MitigaciÃ³n**: Usar features de perfil, popularidad como fallback

3. **Model drift**

   - **Riesgo**: Modelo se vuelve obsoleto con el tiempo
   - **MitigaciÃ³n**: Re-entrenamiento periÃ³dico (semanal/mensual)

4. **Latencia en producciÃ³n**

   - **Riesgo**: Predicciones muy lentas
   - **MitigaciÃ³n**: Cache agresivo, pre-computar embeddings

5. **Sesgo en recomendaciones**
   - **Riesgo**: Solo recomendar actividades populares
   - **MitigaciÃ³n**: MÃ©tricas de diversidad, penalizaciÃ³n de popularidad

### 12.2 Plan de Contingencia

- **Fallback**: Sistema actual siempre disponible
- **Rollback**: Capacidad de volver a versiÃ³n anterior del modelo
- **Monitoring**: Alertas tempranas de degradaciÃ³n

---

## 13. PrÃ³ximos Pasos Inmediatos

### 13.1 Esta Semana

1. âœ… Revisar y aprobar este diseÃ±o
2. âœ… Definir prioridades de implementaciÃ³n
3. âœ… Asignar recursos (desarrollador ML)

### 13.2 Este Mes

1. âœ… Crear tablas de eventos en base de datos
2. âœ… Implementar tracking bÃ¡sico
3. âœ… Establecer Feature Store
4. âœ… Recopilar primeros 1000 eventos

### 13.3 PrÃ³ximos 3 Meses

1. âœ… Entrenar primer modelo MVP
2. âœ… Validar enfoque con datos reales
3. âœ… Preparar integraciÃ³n con backend

---

## 14. ConclusiÃ³n

Este diseÃ±o propone un sistema de recomendaciÃ³n basado en ML que:

1. âœ… **Aprovecha datos existentes**: Usa features ya disponibles
2. âœ… **Escala gradualmente**: De simple a complejo segÃºn datos disponibles
3. âœ… **Mitiga riesgos**: Fallback y monitoreo continuo
4. âœ… **Es prÃ¡ctico**: Roadmap realista y alcanzable

**RecomendaciÃ³n**: Empezar con **Factorization Machines** como MVP, evolucionar a **Two-Tower Neural Network** cuando tengamos suficientes datos.

---

**Documento creado por**: AI Assistant  
**Fecha**: Noviembre 2024  
**VersiÃ³n**: 1.0  
**Estado**: Propuesta - Pendiente de RevisiÃ³n
